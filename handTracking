import cv2
import mediapipe as mp

# Initialize the hand tracking module
mp_hands = mp.solutions.hands
hands = mp_hands.Hands()

# Initialize the drawing module for visualization
mp_drawing = mp.solutions.drawing_utils #permet de dessiner des repères sur les mains détectées pour la visualisation.

# Initialize the webcam for capturing video
cap = cv2.VideoCapture(0)

while True:
    # Read a frame from the webcam
    ret, frame = cap.read()
    if not ret:
        break

    # Convert the BGR frame to RGB for processing with mediapipe
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Process the frame to detect hands
    results = hands.process(rgb_frame)

    # If hands are detected, draw landmarks on the frame : Si des mains sont détectées, les repères sont dessinés sur l'image à l'aide de mp_drawing.draw_landmarks().
    if results.multi_hand_landmarks:
        for landmarks in results.multi_hand_landmarks:
            mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)
#L'image traitée est affichée à l'aide de cv2.imshow().
#La boucle continue jusqu'à ce que la touche 'q' soit enfoncée.
    # Display the frame
    cv2.imshow('Hand Tracking', frame)

    # Exit the loop if the 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close windows
cap.release()
cv2.destroyAllWindows()
